{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multitasking in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Out of the box, Python works in a **sequential** way, which means, it does **one thing at a time**, one after another. If the program has to wait for some reason (e.g. a http request) it does not do anything else than waiting.\n",
    "\n",
    "Another important fact: Python uses one **single core** only. If you have a lot to calculate, Python does not automatically distribute the work for you on multiple cores.\n",
    "\n",
    "If we want to do things faster by implementing multitasking in Python, we first have to solve these questions:\n",
    "\n",
    "* is the bottleneck **CPU** bound (lot of calculations, compressing, etc.)?\n",
    "* is the bottleneck **IO** bound (waiting for network, slow harddisk)?\n",
    "\n",
    "In order to understand multitasking a bit better, we need to clarify some **general concepts**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parallelism\n",
    "\n",
    "* doing calculations in parallel instead of sequential\n",
    "* using more than one CPU\n",
    "* hope we reach the solution in less wallclock time\n",
    "* parallelism is a concept from the **solution domain**\n",
    "\n",
    "**Examples**\n",
    "\n",
    "* parse many files simultaneously\n",
    "* distribute a computational task over many processors or nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Asynchrony\n",
    "* reacting to things that will happen in future\n",
    "* we do not know when these things will happen\n",
    "* asynchrony is **event driven**\n",
    "\n",
    "**Examples**\n",
    "\n",
    "* onClick mousevents in the browser\n",
    "* File change notifications\n",
    "* Incoming requests to a server\n",
    "* Incoming packets of data to a socket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Concurrency\n",
    "* several computations are executed concurrently – during overlapping time periods – instead of sequentially\n",
    "* concurrency control: coordinate access to a shared resource\n",
    "* concurrency is often a part of the **problem domain**\n",
    "\n",
    "**Examples**\n",
    "* booking system for a flight\n",
    "* banking account\n",
    "* database updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementation concepts\n",
    "\n",
    "To make things more challenging, Python offers various implementations. I tried to group them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### threading\n",
    "\n",
    "* run several «trains of thought» on a single processor\n",
    "* **pre-emptive multitasking**\n",
    "* The operating system knows about each thread and can interrupt it at any time to start running a different thread\n",
    "* The OS decides when to switch tasks\n",
    "* implemented in the [threading](https://docs.python.org/3/library/threading.html) module, using a [Queue](https://docs.python.org/3/library/queue.html#module-queue) to tackle concurrency problems\n",
    "* implemented in the [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) module, using the [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor)\n",
    "* suitable for typical IO problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### asyncio\n",
    "\n",
    "* run several «trains of thought» on a single processor\n",
    "* **cooperative multitasking**\n",
    "* the tasks must cooperate by announcing when they are ready to be switched out\n",
    "* the tasks decide when to give up control\n",
    "* this concept has been implemented in many languages\n",
    "* implemented in Python using the [asyncio](https://docs.python.org/3/library/asyncio.html) module and the `async` and `await` syntax\n",
    "* suitable for IO problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### multiprocessing\n",
    "\n",
    "* run several «trains of thought» at the same time, using **multiple processors**\n",
    "* Python creates **new processes** – a collection of resources where the resources include memory, file handles etc\n",
    "* each process runs in its own Python interpreter\n",
    "* implemented in the [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) module, using a [Queue](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue) to tackle concurrency problems\n",
    "* implemented in the [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) module, using the [ProcessPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor)\n",
    "* suitable for CPU problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Links** for further reading:\n",
    "\n",
    "* https://realpython.com/python-concurrency/#what-is-concurrency\n",
    "* https://realpython.com/async-io-python/#async-io-is-not-easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Retrieve data from websites sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def download_site(url, session):\n",
    "    with session.get(url) as response:\n",
    "        print(f\"Read {len(response.content)} from {url}\")\n",
    "\n",
    "\n",
    "def download_all_sites(sites):\n",
    "    with requests.Session() as session:\n",
    "        for url in sites:\n",
    "            download_site(url, session)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sites = [\n",
    "        \"https://www.jython.org\",\n",
    "        \"http://olympus.realpython.org/dice\",\n",
    "    ] * 80\n",
    "    start_time = time.time()\n",
    "    download_all_sites(sites)\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Downloaded {len(sites)} in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Retrieve data from websites using many threads: `concurrent.futures`\n",
    "\n",
    "The new `concurrent.futures` module is a convenient way to achieve threading with not too much headaches. We simply have to define the maximum amount of workers, the queue is set up automatically for us.\n",
    "\n",
    "Try to set the workers to 1 and see what happens. Increase the workers. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "import threading\n",
    "import time\n",
    "\n",
    "thread_local = threading.local()\n",
    "\n",
    "def get_session():\n",
    "    if not hasattr(thread_local, \"session\"):\n",
    "        thread_local.session = requests.Session()\n",
    "    return thread_local.session\n",
    "\n",
    "\n",
    "def download_site(url):\n",
    "    session = get_session()\n",
    "    with session.get(url) as response:\n",
    "        print(f\"Read {len(response.content)} from {url}\")\n",
    "\n",
    "\n",
    "def download_all_sites(sites):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        result = executor.map(download_site, sites)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sites = [\n",
    "        \"https://www.jython.org\",\n",
    "        \"http://olympus.realpython.org/dice\",\n",
    "    ] * 80\n",
    "    start_time = time.time()\n",
    "    download_all_sites(sites)\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Downloaded {len(sites)} in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Threading problems with global variables\n",
    "\n",
    "Not everything is thread safe. The following example illustrates this: it lets 10 workers in our `ThreadPoolExecutor` try to increment a global counter (twice each).\n",
    "In the end, we would expect a `counter` value of `10 x 2 = 20`. But is it? Run the example below a few times (you can hit CTRL+Enter to stay in the same cell). What do you observe?\n",
    "\n",
    "Also try adjusting `sleep(0.0001)` a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from time import sleep\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def increment_counter():\n",
    "    global counter\n",
    "    for _ in range(2):\n",
    "        current_counter_value = counter\n",
    "        sleep(0.0001) # delay between read and write\n",
    "        counter = current_counter_value + 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fake_data = list(range(5000))\n",
    "    counter = 0\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=500) as executor:\n",
    "        tasks = [executor.submit(increment_counter) for _ in range(10)]\n",
    "        for task in tasks:\n",
    "            task.result()\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Showcase the `asyncio` module: a gentle introduction\n",
    "\n",
    "The `asyncio` module implements the Asynchronous I/O framework that can be found in many languages (JavaScript, C++, Java, Raku, etc.). Two new language elements are introduced:\n",
    "\n",
    "* `async`: declares a function to act as a **coroutine**, short for **cooperative routine**. It means, the function announces when it is going to finish\n",
    "* `await`: a marker: wait here until the function returns, in the meantime you can continue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def worker():\n",
    "    print(\"I am working\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"I am working some more...\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"5:30 pm! Time to go home!\")\n",
    "\n",
    "async def main():\n",
    "    await worker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Notice:** In a normal script, you would use `asyncio.run(main())` to start the **main event loop** with our `main` method. But this throws an error:\n",
    "\n",
    "```\n",
    " asyncio.run() cannot be called from a running event loop\n",
    "```\n",
    "\n",
    "(If you are using Python 3.6, you need a [different syntax](https://docs.python.org/3.6/library/asyncio-task.html) to start the main event loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Because we are in **Jupyter**, a main event loop has already started for us, so we can use `await` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Not very exciting, is it? Not any different than sequential programming. But what happens if we add **second worker**?\n",
    "\n",
    "We can achieve this with `asyncio.gather(tasks)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "    asyncio.gather(worker(), worker(), worker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "While the first worker starts sleeping, the second starts working, goes to sleep, passes the thread back to worker 1, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Showcase the `asyncio` module: doing things independently of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look at a more real-life example: we would like to **read a book** and **check our whatsapp** at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def reading_book():\n",
    "    print(\"reading page 1\")\n",
    "    await asyncio.sleep(4)\n",
    "    print(\"reading page 2\")\n",
    "    await asyncio.sleep(4)\n",
    "    print(\"reading page 3\")\n",
    "    await asyncio.sleep(4)\n",
    "    print(\"reading page 4\")\n",
    "    \n",
    "async def seconds():\n",
    "    i = 0\n",
    "    while True:\n",
    "        print(f\"\\t{i} seconds\")\n",
    "        i += 1\n",
    "        await asyncio.sleep(1)\n",
    "        if i > 20:\n",
    "            break\n",
    "\n",
    "async def checking_whatsapp():\n",
    "    print(\"reading new message 1\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"reading new message 2\")\n",
    "    await asyncio.sleep(4)\n",
    "    print(\"reading new message 3\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"reading new message 4\")\n",
    "    \n",
    "async def main(tasks):\n",
    "    await asyncio.gather(*[task for task in tasks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "await main([reading_book(), checking_whatsapp(), seconds()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Showcase the `asyncio` module: things depend on each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "\n",
    "async def part1(n: int) -> str:\n",
    "    i = random.randint(0, 10)\n",
    "    print(f\"part1({n}) sleeping for {i} seconds.\")\n",
    "    await asyncio.sleep(i)\n",
    "    result = f\"result{n}-1\"\n",
    "    print(f\"Returning part1({n}) == {result}.\")\n",
    "    return result\n",
    "\n",
    "async def part2(n: int, arg: str) -> str:\n",
    "    i = random.randint(0, 10)\n",
    "    print(f\"part2{n, arg} sleeping for {i} seconds.\")\n",
    "    await asyncio.sleep(i)\n",
    "    result = f\"result{n}-2 derived from {arg}\"\n",
    "    print(f\"Returning part2{n, arg} == {result}.\")\n",
    "    return result\n",
    "\n",
    "async def chain(n: int) -> None:\n",
    "    start = time.perf_counter()\n",
    "    p1 = await part1(n)\n",
    "    p2 = await part2(n, p1)\n",
    "    end = time.perf_counter() - start\n",
    "    print(f\"-->Chained result{n} => {p2} (took {end:0.2f} seconds).\")\n",
    "\n",
    "async def main(*args):\n",
    "    await asyncio.gather(*(chain(n) for n in args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(444)   # setting the seed to a specific value allows to reproduce randomness :)\n",
    "args = [1,2,3]\n",
    "await main(*args)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
