{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open and close files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### always use the `with` statement to open a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until Python 2.5, the usual way to open a file and write something into it was like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"say_hi.txt\", \"w\")\n",
    "print(\"hi\", file=fh)\n",
    "print(\"ho\", file=fh)\n",
    "not_allowed = 1/0     # simulate the real world: an error happens druring the write process\n",
    "\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat say_hi.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what has been written to the file? Nothing! The file is empty. This is because the content is still in a memory buffer which has not been _flushed_ to the file. We can enforce the `flush=True` by providing this attribute to the `print` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"say_hi.txt\", \"w\")\n",
    "print(\"hi\", file=fh, flush=True)\n",
    "print(\"ho\", file=fh, flush=True)\n",
    "not_allowed = 1/0     # simulate the real world: an error happens druring the write process\n",
    "\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, this is error prone, a lot to type and easy to forget.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `with` statement is a safe way to open a file and write content. If anything happens during the writing process, the memory buffer gets automatically flushed and written to the file, and the file gets closed properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"say_hi.txt\", \"w\", encoding=\"utf-8\") as file_handle_1:\n",
    "    print(\"I ❤︎ ♚ and ♛\", file=file_handle_1)\n",
    "    not_allowed = 1/0     # still creates an error, but now the content is already saved!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still receive the error, but at least our content has now reached its destiny:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat say_hi.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read from one file, write to another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `with` statement also allows to open multiple files at the same time, allowing to copy content safely. **Note:** The backslash `\\` at the end of line 1 is needed to break the statement in two separate lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"say_hi.txt\", \"r\", encoding=\"utf-8\") as file_handle_1, \\\n",
    "     open(\"say_out.txt\", \"w\", encoding=\"utf-8\") as file_handle_2:\n",
    "    \n",
    "    content = file_handle_1.read()   # read in all content\n",
    "    content = content.rstrip(\"\\n\")\n",
    "    \n",
    "    for i in range(1,11):\n",
    "        print(f\"{i}:\\t{content}\", file=file_handle_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat say_out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read line by line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a `readline()` method available which does what it says on the lid: it reads a line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"say_out.txt\", \"r\", encoding=\"utf-8\") as file_handle_2:\n",
    "    myline = file_handle_2.readline()\n",
    "    while myline:\n",
    "        print(myline, end=\"\")  # the line already contains a newline, so we set end=\"\" to avoid double newlines\n",
    "        myline = file_handle_2.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not really convenient. Why not using **a for loop** instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"say_out.txt\", \"r\", encoding=\"utf-8\") as file_handle_2:\n",
    "    for line in file_handle_2:\n",
    "        print(line, end=\"\")   # the line already contains a newline, so we set end=\"\" to avoid double newlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get all lines of a file as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for this task we could use the `readlines()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"say_out.txt\", \"r\", encoding=\"utf-8\") as file_handle_2:\n",
    "    all_lines = file_handle_2.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost. We still have the unecessary newline in every item, which we want to get rid of. And we might want to get rid of the numbers and the tabs, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"say_out.txt\", \"r\", encoding=\"utf-8\") as file_handle_2:\n",
    "    all_lines = [line.rstrip('\\n').split(\"\\t\")[1] for line in file_handle_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line above is rather compact. It contains:\n",
    "\n",
    "1. A list comprehension: `for line in file_handle_2`\n",
    "2. for every `line` we remove the newline, using `line.rstrip(\"\\n\")` method\n",
    "3. the remaining string is splitted by the tabulator character: `split(\"\\t\")`\n",
    "4. the `split` command returns a list, and because we are only interested in the second column, we add `[1]`\n",
    "\n",
    "Voilà!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world logfile parsing using regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real world is a bit more complicated and does not match the training examples. Sysadmins use `grep`, `awk` and `sed` to extract parts of a logfile and pipe the output into another. However, these one-liners become unreadable line-noise. Here is an example how you would extract information from a logfile, using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open the `sfbios.log` in the filebrowser, so you can get an idea what kind of logfile we are dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now somebody (i.e. your boss) would like to extract a list of all sip usernames. The sip usernames can be found in a structure like this:\n",
    "\n",
    "`<property name=\"uri\">sip:rolands@tdl.lv</property>`\n",
    "\n",
    "The logfile is encoded in utf-8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGEX best practises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Always use the extended regular expression syntax with `re.X`, unless the regex is really trivial.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say, someone built a super regular expression which does some very smart extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile('^(?P<alias_alternative>(?P<requested_entity>sample|object)(\\.(?P<attribute>\\w+))?)(\\s+(?i)AS\\s+(?P<alias>\\w+))?\\s*$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `re.X` flag, you can use the extended syntax and comment every piece of your regular expression separately. The same regex as above is now much easier to read and comprehend, the original intention is preserved. Because you can span the regex over many lines, you also need to specify all whitespace explicitly with `\\s` or `\\s+`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\n",
    "    r\"\"\"^                                              # beginning of the string\n",
    "        (?P<alias_alternative>                         # use first part as alias, if no alias is defined\n",
    "          (?P<requested_entity>sample|object)          # string starts with sample or object\n",
    "          (\\.(?P<attribute>\\w+))?                      # capture an optional .attribute\n",
    "        )\n",
    "        (                                              # capture an optional alias: entity.attribute AS alias\n",
    "          \\s+(?i)AS\\s+                                 # whitespace, ignore case of 'AS', whitespace\n",
    "          (?P<alias>\\w+)                               # capture the alias\n",
    "        )?                                             # \n",
    "        \\s*                                            # ignore any trailing whitespace\n",
    "        $                                              # end of string\n",
    "    \"\"\",\n",
    "    re.X + re.I\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do not use `re.match`, always use `re.search`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This regular expression below does **not match anything**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "line = \"Cats are smarter than dogs\"\n",
    "re.match(\"dogs$\", line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but this **does**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "line = \"Cats are smarter than dogs\"\n",
    "re.search(\"dogs$\", line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why?** The difference between `re.match()` and `re.search()` is that `re.match()` behaves as if every pattern has `\\A` prepended (or `^` if you don't use multiline). Anyone accustomed to Perl, grep, or sed regular expression matching is mislead by `re.match()`.\n",
    "\n",
    "There is actually a reason why re.match exists at all: it is **speed**. When `re.search()` is used and no matching is possible, it takes a considerable amount [more time](https://stackoverflow.com/questions/29007197/why-have-re-match) than `re.match()` until the matching fails. I am inclined to say: Python has an implementation problem here. I think `re.match()` should better be *deprecated*, because it leads to unnecessary problems, despite the speed gain one might observe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make use of **named capture groups**\n",
    "\n",
    "A very common practice is to group elements in a regular expression:\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "url = '/some/url/our_first_parameter/our_second_parameter'\n",
    "match = re.search(\"^/some/url/((.*?)/(.*?))$\", url)\n",
    "match.groups()\n",
    "\n",
    "# returns\n",
    "('our_first_parameter/our_second_parameter',\n",
    " 'our_first_parameter',\n",
    " 'our_second_parameter')\n",
    "```\n",
    "\n",
    "However, this leads to the problem that the parameters fetched are positional.  If you have nested group captures, you have to count the number of the opening round brackets `(` to get the position of every parameter right. And if you decide to remove a grouping later, you will have to check every position again.\n",
    "\n",
    "\n",
    "Instead, you would rather give your groups a name so you can easily rearrange your groupings without having to worry about their positions:\n",
    "<strong>\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "url = '/some/url/our_first_parameter/our_second_parameter'\n",
    "match = re.search(r\"\"\"\n",
    "    ^                       # beginning of the string\n",
    "    /some/url/              # match the base-url\n",
    "    (\n",
    "      ?P<the_whole_thing>   # capture both parameters\n",
    "      (?P<param1>.*?)       # capture the first parameter only\n",
    "      /                     # ... followed by a /\n",
    "      (?P<param2>.*?)       # capture the second parameter only\n",
    "    )\n",
    "    $                       # end of the string\n",
    "    \"\"\", url, re.X)\n",
    "if (match):\n",
    "    print(match.groupdict())\n",
    "\n",
    "# returns\n",
    "{\n",
    "    'the_whole_thing': 'our_first_parameter/our_second_parameter',\n",
    "    'param1': 'our_first_parameter',\n",
    "    'param2': 'our_second_parameter'\n",
    "}\n",
    "```\n",
    "</strong>\n",
    "\n",
    "This leads to much more robust regular expressions, especially when we are adding new or removing existing captures.\n",
    "\n",
    "In **substitutions** or within regular expressions, named capture groups are back-referenced by\n",
    "\n",
    "```\n",
    "\\g<the_name_of_the_captured_group>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### back to the real-world problem..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now back to our real problem, we will use this extended regex syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(r'''\n",
    "    <property\\s name=\"uri\">  # beginning of the property element\n",
    "    (?P<sip>.*?)             # fetch content, put it named capture group «sip»\n",
    "    <\\/property>             # end of element\n",
    "    ''', re.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    "regex = re.compile(r'''\n",
    "    <property\\s name=\"uri\">  # beginning of element\n",
    "    (?P<sip>.*?)             # fetch content, put it named capture group «sip»\n",
    "    <\\/property>             # end of element\n",
    "    ''', re.X)\n",
    "\n",
    "log_file_path = \"sfbios.log\"\n",
    "\n",
    "match_list = []\n",
    "with open(log_file_path, \"r\", encoding=\"utf-8\") as logfile_handle, \\\n",
    "     open(\"sip_list\", \"w\") as output_handle:\n",
    "    for line in logfile_handle:\n",
    "        match = regex.search(line)    # BE AWARE: always use re.search, NEVER re.match!\n",
    "        if match:\n",
    "            print(match.groupdict()['sip'], file=output_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat sip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
